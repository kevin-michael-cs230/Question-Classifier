{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Todo: Fix dataset imbalance. There are 1244 positive training examples, and 901 negative training examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: sentencepiece in /home/herrerx/.local/lib/python3.7/site-packages (0.1.95)\n"
     ]
    }
   ],
   "source": [
    "# Install sentencenpiece to help in tokenization\n",
    "!pip install sentencepiece"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow import keras\n",
    "import transformers\n",
    "import numpy as np\n",
    "from os import path\n",
    "import pandas as pd\n",
    "from transformers import AutoTokenizer, TFXLNetModel, TFAutoModel, TFXLNetForSequenceClassification\n",
    "\n",
    "DATA_DIR = 'datasets'\n",
    "DATASET_PATH = 'labels_with_stackx.csv'\n",
    "TOKENIZED_DATASET_PATH = 'labels_with_stackx_tokenized'\n",
    "TRAIN_SET = 'train_set'\n",
    "DEV_SET = 'dev_set'\n",
    "TEST_SET = 'test_set'\n",
    "STACKX_COLUMNS = [\n",
    "    'question_asker_intent_understanding',\n",
    "     'question_body_critical',\n",
    "     'question_conversational',\n",
    "     'question_expect_short_answer',\n",
    "     'question_fact_seeking',\n",
    "     'question_has_commonly_accepted_answer',\n",
    "     'question_interestingness_others',\n",
    "     'question_interestingness_self',\n",
    "     'question_multi_intent',\n",
    "     'question_not_really_a_question',\n",
    "     'question_opinion_seeking',\n",
    "     'question_type_choice',\n",
    "     'question_type_compare',\n",
    "     'question_type_consequence',\n",
    "     'question_type_definition',\n",
    "     'question_type_entity',\n",
    "     'question_type_instructions',\n",
    "     'question_type_procedure',\n",
    "     'question_type_reason_explanation',\n",
    "     'question_type_spelling',\n",
    "     'question_well_written'\n",
    "]\n",
    "NUM_SX_FEATURES = len(STACKX_COLUMNS)\n",
    "\n",
    "\n",
    "TRAIN_RATIO = .6\n",
    "DEV_RATIO = .2\n",
    "TEST_RATIO = .2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Value of 0.000001 and 2 epochs lead to 58% on training and 54.5% on dev. \n",
    "Further training did not lead to higher accuracy\n",
    "\n",
    "Tried seeing of model had capacity to fit. Ran 6 epochs on 100 training examples\n",
    "to see if I could at least get it to overfit. loss: 0.6451 - accuracy: 0.6222\n",
    "Dev: loss: 0.6841 - accuracy: 0.5566\n",
    "\n",
    "Ran 6 epochs on 200 training examples. loss: 0.6424 - accuracy: 0.6300\n",
    "Dev: loss: 0.6874 - accuracy: 0.5524\n",
    "Then another 6 epcohs on another 100 training examples. loss: 0.6233 - accuracy: 0.6200\n",
    "Dev: loss: 0.7047 - accuracy: 0.5594\n",
    "Then another 3 epochs on another 400 examples. loss: 0.6606 - accuracy: 0.5725\n",
    "Dev: loss: 0.7007 - accuracy: 0.5650\n",
    "Then another 3 epochs on another 500 examples. loss: 0.6486 - accuracy: 0.6300\n",
    "Dev: loss: 0.6761 - accuracy: 0.5944\n",
    "Then another epoch on entire training set. loss: 0.6507 - accuracy: 0.6247\n",
    "Dev: loss: 0.6624 - accuracy: 0.6238\n",
    "Then another epoch on entire training set. 0.6324 - accuracy: 0.6424\n",
    "Dev: loss: 0.7089 - accuracy: 0.5986 <- We've reached the point of overfit\n",
    "\n",
    "Ran 8 epochs on 100 examples with \n",
    "lr_schedule = tf.keras.optimizers.schedules.ExponentialDecay(\n",
    "    1e-5,\n",
    "    decay_steps=50,\n",
    "    decay_rate=0.9,\n",
    "    staircase=True\n",
    ")\n",
    "Successfully overfit the model\n",
    "\n",
    "With exponential decay, model appears to start overfitting after epoch 2.\n",
    "Holding back 60 examples from the test set for validation after each epoch seems to match dev set well.\n",
    "\n",
    "After further inspection, it appears that the model just leans toward always predicing positive because \n",
    "there are more positive than negative examples. This suggests that there is not a meaningful correlation in the data.\n",
    "For example, trained a model and got 54% accuracy on dev set. Number of positive and negative predictions were\n",
    "Positives: 711 Negatives: 4\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "MAX_LEN = 1024\n",
    "LEARNING_RATE = 0.000001 \n",
    "BATCH_SIZE = 2\n",
    "EPOCHS = 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper functions for tokenizing a dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_processed_dataframe(path: str) -> pd.DataFrame:\n",
    "    \n",
    "    data = pd.read_csv(path)\n",
    "    \n",
    "    # Drop all rows with questions that are not understandable\n",
    "    data.drop(data[data.understandable == 0].index, inplace=True)\n",
    "    # All questions are understandable so we can remove the 'understandable' column\n",
    "    data.drop(columns=\"understandable\", inplace=True)\n",
    "    # Remove rows whos passage has more than 'max_len' words\n",
    "    data.drop(data[data.passage.map(lambda x: x.count(\" \") + 1) > MAX_LEN].index, inplace=True)\n",
    "    # Remove rows with a comprehension value of 3, because these values won't work for binary classification\n",
    "    data.drop(data[data.comprehension == 3].index, inplace=True)\n",
    "    \n",
    "    return data\n",
    "\n",
    "# Create a closure for tokenization\n",
    "\n",
    "def get_tokenize_func():\n",
    "\n",
    "    tokenizer = AutoTokenizer.from_pretrained('xlnet-base-cased', model_max_length=MAX_LEN)\n",
    "  \n",
    "    def tk(df):\n",
    "        out = tokenizer(df['passage'], df['question'], padding='max_length', truncation=True)\n",
    "        return out['input_ids'], out['token_type_ids'], out['attention_mask']\n",
    "  \n",
    "    return tk\n",
    "\n",
    "def get_tokens(data: pd.DataFrame):\n",
    "    data['output_ids'], data['token_type_ids'], data['attention_mask'] = zip(*data.apply(get_tokenize_func(), axis=1))\n",
    "    for col in ['output_ids', 'token_type_ids', 'attention_mask']:\n",
    "        data[col] = data[col].apply(lambda cell: np.array(cell))\n",
    "    \n",
    "def tokenize_and_save(load_path: str, save_path: str):\n",
    "    data = get_processed_dataframe(load_path)\n",
    "    get_tokens(data)\n",
    "    data.to_pickle(save_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper functions for splitting a numpy arrays for train, dev and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_datasets(rerun_tokenization=False):\n",
    "    # Uncomment the following line of code if you would like to re-run the tokenization process\n",
    "    if rerun_tokenization:\n",
    "        tokenize_and_save(path.join(DATA_DIR, DATASET_PATH), path.join(DATA_DIR, TOKENIZED_DATASET_PATH))\n",
    "    \n",
    "    tokenized_data = pd.read_pickle(path.join(DATA_DIR, TOKENIZED_DATASET_PATH))\n",
    "    \n",
    "    # Randomly shuffle the data, but seeded so it's repeatable\n",
    "    tokenized_data = tokenized_data.sample(frac=1, random_state=1)\n",
    "\n",
    "    # Get train, test, dev splits\n",
    "    num_entries = len(tokenized_data)\n",
    "    train_cutoff = int(num_entries * TRAIN_RATIO)\n",
    "    dev_cutoff = train_cutoff + int(num_entries * DEV_RATIO)\n",
    "\n",
    "    train_set = tokenized_data[:train_cutoff]\n",
    "    dev_set = tokenized_data[train_cutoff:dev_cutoff]\n",
    "    test_set = tokenized_data[dev_cutoff:]\n",
    "\n",
    "    train_set.to_pickle(path.join(DATA_DIR, TRAIN_SET))\n",
    "    dev_set.to_pickle(path.join(DATA_DIR, DEV_SET))\n",
    "    test_set.to_pickle(path.join(DATA_DIR,TEST_SET))\n",
    "    \n",
    "def get_features(df: pd.DataFrame) -> list:\n",
    "    output_ids = np.stack(df['output_ids'].values)\n",
    "    token_type_ids = np.stack(df['token_type_ids'].values)\n",
    "    attention_mask = np.stack(df['attention_mask'].values)\n",
    "    stackx_features = np.stack(df[STACKX_COLUMNS].values)\n",
    "    return [output_ids, token_type_ids, attention_mask, stackx_features]\n",
    "    \n",
    "def get_labels(df: pd.DataFrame, label_name: str):\n",
    "    # Extract numpy array, and reshape to be rank-2\n",
    "    return np.reshape(df[label_name].values, (-1, 1))\n",
    "    \n",
    "def get_datasets():\n",
    "    train_set = pd.read_pickle(path.join(DATA_DIR, TRAIN_SET))\n",
    "    dev_set = pd.read_pickle(path.join(DATA_DIR, DEV_SET))\n",
    "    test_set = pd.read_pickle(path.join(DATA_DIR,TEST_SET))\n",
    "    \n",
    "    return train_set, dev_set, test_set\n",
    "\n",
    "\n",
    "def get_subset(ftrs: list, start: int, stop: int) -> list:\n",
    "    return [ftrs[0][start:stop], ftrs[1][start:stop], ftrs[2][start:stop], ftrs[3][start:stop]]\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_datasets(rerun_tokenization=False)\n",
    "train_set, dev_set, test_set = get_datasets()\n",
    "train_features, train_labels = get_features(train_set), get_labels(train_set, 'comprehension binary')\n",
    "dev_features, dev_labels = get_features(dev_set), get_labels(dev_set, 'comprehension binary')\n",
    "test_features, test_labels = get_features(test_set), get_labels(test_set, 'comprehension binary')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(max_len: int, num_sx_features: int) -> tf.keras.Model:\n",
    "    encoder = TFXLNetForSequenceClassification.from_pretrained('xlnet-base-cased', num_labels=1) #Input is tokenized strings, output is embeddings and logits (logits means pre-sigmoid label)\n",
    "    input_ids = layers.Input(shape=(max_len,), dtype=tf.int32, name='input_ids')\n",
    "    token_type_ids = layers.Input(shape=(max_len,), dtype=tf.int32, name='token_type_ids')\n",
    "    attention_mask = layers.Input(shape=(max_len,), dtype=tf.int32, name='attention_mask')\n",
    "    stackx_features = layers.Input(shape=(num_sx_features,), dtype=tf.float32, name='stackx_features')\n",
    "\n",
    "    logits = encoder(\n",
    "        input_ids, token_type_ids=token_type_ids, attention_mask=attention_mask\n",
    "    ).logits\n",
    "    encoder_preds = layers.Dense(1, activation='sigmoid', name='encoder_preds')(logits)\n",
    "    merged = layers.Concatenate()([encoder_preds, stackx_features])\n",
    "    final_pred = layers.Dense(1, activation='sigmoid', name='final_prediction')(merged)\n",
    "\n",
    "    model = tf.keras.Model(\n",
    "            inputs=[input_ids, token_type_ids, attention_mask, stackx_features],\n",
    "            outputs=[final_pred], name='classifier'\n",
    "        )\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some layers from the model checkpoint at xlnet-base-cased were not used when initializing TFXLNetForSequenceClassification: ['lm_loss']\n",
      "- This IS expected if you are initializing TFXLNetForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFXLNetForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some layers of TFXLNetForSequenceClassification were not initialized from the model checkpoint at xlnet-base-cased and are newly initialized: ['sequence_summary', 'logits_proj']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
      "WARNING:tensorflow:AutoGraph could not transform <bound method Socket.send of <zmq.sugar.socket.Socket object at 0x7fa338d4b050>> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module, class, method, function, traceback, frame, or code object was expected, got cython_function_or_method\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <bound method Socket.send of <zmq.sugar.socket.Socket object at 0x7fa338d4b050>> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: module, class, method, function, traceback, frame, or code object was expected, got cython_function_or_method\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    }
   ],
   "source": [
    "keras.backend.clear_session()\n",
    "model = create_model(MAX_LEN, NUM_SX_FEATURES)\n",
    "lr_schedule = tf.keras.optimizers.schedules.ExponentialDecay(\n",
    "    1e-5,\n",
    "    decay_steps=50,\n",
    "    decay_rate=0.9,\n",
    "    staircase=True\n",
    ")\n",
    "\n",
    "model.compile(optimizer=keras.optimizers.Adam(lr_schedule), loss=keras.losses.BinaryCrossentropy(), metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "feat_subset = get_subset(train_features, 0, 300)\n",
    "lab_subset = train_labels[0:300]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "135/135 [==============================] - 74s 549ms/step - loss: 0.6955 - accuracy: 0.5111 - val_loss: 0.6530 - val_accuracy: 0.5667\n",
      "Epoch 2/2\n",
      "135/135 [==============================] - 74s 548ms/step - loss: 0.6879 - accuracy: 0.5481 - val_loss: 0.6513 - val_accuracy: 0.6000\n"
     ]
    }
   ],
   "source": [
    "hist = model.fit(feat_subset, lab_subset, validation_split=.1,batch_size=BATCH_SIZE, epochs=EPOCHS, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "358/358 [==============================] - 47s 130ms/step - loss: 0.6973 - accuracy: 0.5077\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.6972507834434509, 0.5076923370361328]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(dev_features, dev_labels, batch_size=BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model.save('model_checkpoints/dev62pct')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = model.predict(dev_features, batch_size=BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Positives: 553\n",
      "Negatives: 162\n"
     ]
    }
   ],
   "source": [
    "pos = np.where(out >= .5)\n",
    "neg = np.where(out < .5)\n",
    "print(f'Positives: {pos[0].shape[0]}')\n",
    "print(f'Negatives: {neg[0].shape[0]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dev62pct  dev_ac_59pct\r\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:tensorflow_p37] *",
   "language": "python",
   "name": "conda-env-tensorflow_p37-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

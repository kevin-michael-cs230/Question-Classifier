{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Todo: Fix dataset imbalance. There are 1244 positive training examples, and 901 negative training examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting sentencepiece\n",
      "  Using cached sentencepiece-0.1.95-cp37-cp37m-manylinux2014_x86_64.whl (1.2 MB)\n",
      "Installing collected packages: sentencepiece\n",
      "Successfully installed sentencepiece-0.1.95\n"
     ]
    }
   ],
   "source": [
    "# Install sentencenpiece to help in tokenization\n",
    "!pip install sentencepiece"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow import keras\n",
    "import transformers\n",
    "import numpy as np\n",
    "from os import path\n",
    "import pandas as pd\n",
    "from transformers import AutoTokenizer, TFXLNetModel, TFAutoModel, TFXLNetForSequenceClassification\n",
    "from constants import *\n",
    "from dataframe_utils import tokenize_dataframe\n",
    "from new_model import create_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Value of 0.000001 and 2 epochs lead to 58% on training and 54.5% on dev. \n",
    "Further training did not lead to higher accuracy\n",
    "\n",
    "Tried seeing of model had capacity to fit. Ran 6 epochs on 100 training examples\n",
    "to see if I could at least get it to overfit. loss: 0.6451 - accuracy: 0.6222\n",
    "Dev: loss: 0.6841 - accuracy: 0.5566\n",
    "\n",
    "Ran 6 epochs on 200 training examples. loss: 0.6424 - accuracy: 0.6300\n",
    "Dev: loss: 0.6874 - accuracy: 0.5524\n",
    "Then another 6 epcohs on another 100 training examples. loss: 0.6233 - accuracy: 0.6200\n",
    "Dev: loss: 0.7047 - accuracy: 0.5594\n",
    "Then another 3 epochs on another 400 examples. loss: 0.6606 - accuracy: 0.5725\n",
    "Dev: loss: 0.7007 - accuracy: 0.5650\n",
    "Then another 3 epochs on another 500 examples. loss: 0.6486 - accuracy: 0.6300\n",
    "Dev: loss: 0.6761 - accuracy: 0.5944\n",
    "Then another epoch on entire training set. loss: 0.6507 - accuracy: 0.6247\n",
    "Dev: loss: 0.6624 - accuracy: 0.6238\n",
    "Then another epoch on entire training set. 0.6324 - accuracy: 0.6424\n",
    "Dev: loss: 0.7089 - accuracy: 0.5986 <- We've reached the point of overfit\n",
    "\n",
    "Ran 8 epochs on 100 examples with \n",
    "lr_schedule = tf.keras.optimizers.schedules.ExponentialDecay(\n",
    "    1e-5,\n",
    "    decay_steps=50,\n",
    "    decay_rate=0.9,\n",
    "    staircase=True\n",
    ")\n",
    "Successfully overfit the model\n",
    "\n",
    "With exponential decay, model appears to start overfitting after epoch 2.\n",
    "Holding back 60 examples from the test set for validation after each epoch seems to match dev set well.\n",
    "\n",
    "After further inspection, it appears that the model just leans toward always predicing positive because \n",
    "there are more positive than negative examples. This suggests that there is not a meaningful correlation in the data.\n",
    "For example, trained a model and got 54% accuracy on dev set. Number of positive and negative predictions were\n",
    "Positives: 711 Negatives: 4\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "TRAIN_RATIO = .6\n",
    "DEV_RATIO = .2\n",
    "LEARNING_RATE = 0.000001 \n",
    "BATCH_SIZE = 2\n",
    "EPOCHS = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_datasets(rerun_tokenization=False):\n",
    "    # Uncomment the following line of code if you would like to re-run the tokenization process\n",
    "    if rerun_tokenization:\n",
    "        tokenize_and_save(path.join(DATA_DIR, DATASET_PATH), path.join(DATA_DIR, TOKENIZED_DATASET_PATH))\n",
    "    \n",
    "    tokenized_data = pd.read_pickle(path.join(DATA_DIR, TOKENIZED_DATASET_PATH))\n",
    "    \n",
    "    # Randomly shuffle the data, but seeded so it's repeatable\n",
    "    tokenized_data = tokenized_data.sample(frac=1, random_state=1)\n",
    "\n",
    "    # Get train, test, dev splits\n",
    "    num_entries = len(tokenized_data)\n",
    "    train_cutoff = int(num_entries * TRAIN_RATIO)\n",
    "    dev_cutoff = train_cutoff + int(num_entries * DEV_RATIO)\n",
    "\n",
    "    train_set = tokenized_data[:train_cutoff]\n",
    "    dev_set = tokenized_data[train_cutoff:dev_cutoff]\n",
    "    test_set = tokenized_data[dev_cutoff:]\n",
    "\n",
    "    train_set.to_pickle(path.join(DATA_DIR, TRAIN_SET))\n",
    "    dev_set.to_pickle(path.join(DATA_DIR, DEV_SET))\n",
    "    test_set.to_pickle(path.join(DATA_DIR,TEST_SET))\n",
    "\n",
    "def get_subset(ftrs: list, start: int, stop: int) -> list:\n",
    "    return [ftrs[0][start:stop], ftrs[1][start:stop], ftrs[2][start:stop], ftrs[3][start:stop]]\n",
    "\n",
    "def get_processed_dataframe(path: str) -> pd.DataFrame:\n",
    "    \n",
    "    data = pd.read_csv(path)\n",
    "    \n",
    "    # Drop all rows with questions that are not understandable\n",
    "    data.drop(data[data.understandable == 0].index, inplace=True)\n",
    "    # All questions are understandable so we can remove the 'understandable' column\n",
    "    data.drop(columns=\"understandable\", inplace=True)\n",
    "    # Remove rows whos passage has more than 'max_len' words\n",
    "    data.drop(data[data.passage.map(lambda x: x.count(\" \") + 1) > MAX_LEN].index, inplace=True)\n",
    "    # Remove rows with a comprehension value of 3, because these values won't work for binary classification\n",
    "    data.drop(data[data.comprehension == 3].index, inplace=True)\n",
    "    \n",
    "    return data\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'get_datasets' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-16-fdcc2aed8cf3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mcreate_datasets\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrerun_tokenization\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtrain_set\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdev_set\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_set\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_datasets\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mtrain_features\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_labels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_features\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_set\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mget_labels\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_set\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'comprehension binary'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mdev_features\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdev_labels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_features\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdev_set\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mget_labels\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdev_set\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'comprehension binary'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mtest_features\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_labels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_features\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_set\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mget_labels\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_set\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'comprehension binary'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'get_datasets' is not defined"
     ]
    }
   ],
   "source": [
    "create_datasets(rerun_tokenization=False)\n",
    "train_set, dev_set, test_set = get_datasets()\n",
    "train_features, train_labels = get_features(train_set), get_labels(train_set, 'comprehension binary')\n",
    "dev_features, dev_labels = get_features(dev_set), get_labels(dev_set, 'comprehension binary')\n",
    "test_features, test_labels = get_features(test_set), get_labels(test_set, 'comprehension binary')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keras.backend.clear_session()\n",
    "model = create_model(MAX_LEN, NUM_SX_FEATURES)\n",
    "lr_schedule = tf.keras.optimizers.schedules.ExponentialDecay(\n",
    "    1e-5,\n",
    "    decay_steps=50,\n",
    "    decay_rate=0.9,\n",
    "    staircase=True\n",
    ")\n",
    "\n",
    "model.compile(optimizer=keras.optimizers.Adam(lr_schedule), loss=keras.losses.BinaryCrossentropy(), metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "135/135 [==============================] - 74s 549ms/step - loss: 0.6955 - accuracy: 0.5111 - val_loss: 0.6530 - val_accuracy: 0.5667\n",
      "Epoch 2/2\n",
      "135/135 [==============================] - 74s 548ms/step - loss: 0.6879 - accuracy: 0.5481 - val_loss: 0.6513 - val_accuracy: 0.6000\n"
     ]
    }
   ],
   "source": [
    "hist = model.fit(feat_subset, lab_subset, validation_split=.1,batch_size=BATCH_SIZE, epochs=EPOCHS, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'dev_labels' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-1d26d7e6647b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdev_labels\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'dev_labels' is not defined"
     ]
    }
   ],
   "source": [
    "dev_labels[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "358/358 [==============================] - 47s 130ms/step - loss: 0.6973 - accuracy: 0.5077\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.6972507834434509, 0.5076923370361328]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(dev_features, dev_labels, batch_size=BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model.save('model_checkpoints/dev62pct')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = model.predict(dev_features, batch_size=BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Positives: 553\n",
      "Negatives: 162\n"
     ]
    }
   ],
   "source": [
    "pos = np.where(out >= .5)\n",
    "neg = np.where(out < .5)\n",
    "print(f'Positives: {pos[0].shape[0]}')\n",
    "print(f'Negatives: {neg[0].shape[0]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dev62pct  dev_ac_59pct\r\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:tensorflow_p37] *",
   "language": "python",
   "name": "conda-env-tensorflow_p37-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
